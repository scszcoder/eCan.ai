# ============================================================================
# Reusable Workflow: S3 Upload (Single Bucket Design)
# ============================================================================
# This workflow uploads build artifacts to S3 using the single bucket design
# with environment-based path prefixes.
#
# Path Structure:
#   s3://ecan-updates/{environment}/releases/v{version}/{platform}/{arch}/
#
# Usage:
#   jobs:
#     upload:
#       uses: ./.github/workflows/shared-s3-upload-v2.yml
#       with:
#         version: "1.0.0"
#         environment: "production"
#       secrets: inherit
# ============================================================================

name: S3 Upload (Single Bucket)

on:
  workflow_call:
    inputs:
      version:
        description: 'Version string (e.g., 1.0.0, 1.0.0-rc.1)'
        required: true
        type: string
      environment:
        description: 'Target environment (dev/test/staging/production)'
        required: true
        type: string
      windows-build-result:
        description: 'Result of Windows build job'
        required: false
        type: string
        default: 'success'
      macos-build-result:
        description: 'Result of macOS build job'
        required: false
        type: string
        default: 'success'
    outputs:
      upload-success:
        description: 'Whether upload was successful'
        value: ${{ jobs.upload.outputs.success }}

jobs:
  upload:
    name: Upload to S3 (${{ inputs.environment }})
    runs-on: ubuntu-latest
    outputs:
      success: ${{ steps.upload.outputs.success }}
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install boto3 pyyaml
      
      - name: Download all artifacts for S3 transfer
        uses: actions/download-artifact@v4
        with:
          pattern: '*-s3-transfer'
          path: dist/
          merge-multiple: true
      
      - name: List downloaded artifacts
        run: |
          echo "=== Downloaded Artifacts ==="
          ls -lh dist/ || echo "No artifacts found"
      
      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ secrets.AWS_REGION || 'us-east-1' }}
      
      - name: Upload to S3
        id: upload
        env:
          VERSION: ${{ inputs.version }}
          ENVIRONMENT: ${{ inputs.environment }}
        run: |
          echo "=== Uploading to S3 ==="
          echo "Version: $VERSION"
          echo "Environment: $ENVIRONMENT"
          
          # Run upload script
          python3 build_system/scripts/upload_to_s3.py \
            --version "$VERSION" \
            --env "$ENVIRONMENT"
          
          if [ $? -eq 0 ]; then
            echo "success=true" >> $GITHUB_OUTPUT
          else
            echo "success=false" >> $GITHUB_OUTPUT
            exit 1
          fi
