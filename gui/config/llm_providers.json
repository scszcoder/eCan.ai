{
  "providers": {
    "ChatOpenAI": {
      "name": "ChatOpenAI",
      "display_name": "OpenAI",
      "provider": "openai",
      "class_name": "ChatOpenAI",
      "api_key_env_vars": ["OPENAI_API_KEY"],
      "base_url": "https://api.openai.com/v1",
      "default_model": "gpt-4o",
      "description": "OpenAI GPT models including GPT-4, GPT-3.5-turbo",
      "documentation_url": "https://platform.openai.com/docs",
      "is_local": false,
      "supported_models": [
        {
          "name": "gpt-4o",
          "display_name": "GPT-4o",
          "model_id": "gpt-4o",
          "default_temperature": 0.7,
          "max_tokens": 4096,
          "supports_streaming": true,
          "supports_function_calling": true,
          "supports_vision": true,
          "cost_per_1k_tokens": 0.03,
          "description": "Most capable GPT-4 model with vision capabilities"
        },
        {
          "name": "gpt-4o-mini",
          "display_name": "GPT-4o Mini",
          "model_id": "gpt-4o-mini",
          "default_temperature": 0.7,
          "max_tokens": 4096,
          "supports_streaming": true,
          "supports_function_calling": true,
          "supports_vision": true,
          "cost_per_1k_tokens": 0.0015,
          "description": "Smaller, faster, cheaper GPT-4o model"
        },
        {
          "name": "gpt-3.5-turbo",
          "display_name": "GPT-3.5 Turbo",
          "model_id": "gpt-3.5-turbo",
          "default_temperature": 0.7,
          "max_tokens": 4096,
          "supports_streaming": true,
          "supports_function_calling": true,
          "supports_vision": false,
          "cost_per_1k_tokens": 0.002,
          "description": "Fast and efficient model for most tasks"
        }
      ]
    },
    "AzureOpenAI": {
      "name": "AzureOpenAI",
      "display_name": "Azure OpenAI",
      "provider": "azure_openai",
      "class_name": "AzureOpenAI",
      "api_key_env_vars": ["AZURE_ENDPOINT", "AZURE_OPENAI_API_KEY"],
      "base_url": null,
      "default_model": "gpt-4",
      "description": "Azure OpenAI Service",
      "documentation_url": "https://docs.microsoft.com/en-us/azure/cognitive-services/openai/",
      "is_local": false,
      "supported_models": [
        {
          "name": "gpt-4",
          "display_name": "GPT-4 (Azure)",
          "model_id": "gpt-4",
          "default_temperature": 0.7,
          "max_tokens": 4096,
          "supports_streaming": true,
          "supports_function_calling": true,
          "supports_vision": false,
          "cost_per_1k_tokens": 0.03,
          "description": "GPT-4 model via Azure OpenAI Service"
        },
        {
          "name": "gpt-35-turbo",
          "display_name": "GPT-3.5 Turbo (Azure)",
          "model_id": "gpt-35-turbo",
          "default_temperature": 0.7,
          "max_tokens": 4096,
          "supports_streaming": true,
          "supports_function_calling": true,
          "supports_vision": false,
          "cost_per_1k_tokens": 0.002,
          "description": "GPT-3.5 Turbo via Azure OpenAI Service"
        }
      ]
    },
    "ChatAnthropic": {
      "name": "ChatAnthropic",
      "display_name": "Anthropic Claude",
      "provider": "anthropic",
      "class_name": "ChatAnthropic",
      "api_key_env_vars": ["ANTHROPIC_API_KEY"],
      "base_url": "https://api.anthropic.com",
      "default_model": "claude-3-5-sonnet-20241022",
      "description": "Anthropic Claude models",
      "documentation_url": "https://docs.anthropic.com/",
      "is_local": false,
      "supported_models": [
        {
          "name": "claude-3-5-sonnet-20241022",
          "display_name": "Claude 3.5 Sonnet",
          "model_id": "claude-3-5-sonnet-20241022",
          "default_temperature": 0.7,
          "max_tokens": 4096,
          "supports_streaming": true,
          "supports_function_calling": true,
          "supports_vision": true,
          "cost_per_1k_tokens": 0.015,
          "description": "Latest Claude 3.5 Sonnet model with enhanced capabilities"
        },
        {
          "name": "claude-3-haiku-20240307",
          "display_name": "Claude 3 Haiku",
          "model_id": "claude-3-haiku-20240307",
          "default_temperature": 0.7,
          "max_tokens": 4096,
          "supports_streaming": true,
          "supports_function_calling": true,
          "supports_vision": true,
          "cost_per_1k_tokens": 0.0025,
          "description": "Fast and cost-effective Claude model"
        },
        {
          "name": "claude-3-opus-20240229",
          "display_name": "Claude 3 Opus",
          "model_id": "claude-3-opus-20240229",
          "default_temperature": 0.7,
          "max_tokens": 4096,
          "supports_streaming": true,
          "supports_function_calling": true,
          "supports_vision": true,
          "cost_per_1k_tokens": 0.075,
          "description": "Most capable Claude model for complex tasks"
        }
      ]
    },
    "ChatBedrockConverse": {
      "name": "ChatBedrockConverse",
      "display_name": "AWS Bedrock",
      "provider": "bedrock",
      "class_name": "ChatBedrockConverse",
      "api_key_env_vars": ["AWS_ACCESS_KEY_ID", "AWS_SECRET_ACCESS_KEY"],
      "base_url": null,
      "default_model": "anthropic.claude-3-sonnet-20240229-v1:0",
      "description": "AWS Bedrock Converse API",
      "documentation_url": "https://docs.aws.amazon.com/bedrock/",
      "is_local": false,
      "supported_models": [
        {
          "name": "anthropic.claude-3-sonnet-20240229-v1:0",
          "display_name": "Claude 3 Sonnet (Bedrock)",
          "model_id": "anthropic.claude-3-sonnet-20240229-v1:0",
          "default_temperature": 0.7,
          "max_tokens": 4096,
          "supports_streaming": true,
          "supports_function_calling": true,
          "supports_vision": true,
          "cost_per_1k_tokens": 0.015,
          "description": "Claude 3 Sonnet via AWS Bedrock"
        },
        {
          "name": "anthropic.claude-3-haiku-20240307-v1:0",
          "display_name": "Claude 3 Haiku (Bedrock)",
          "model_id": "anthropic.claude-3-haiku-20240307-v1:0",
          "default_temperature": 0.7,
          "max_tokens": 4096,
          "supports_streaming": true,
          "supports_function_calling": true,
          "supports_vision": true,
          "cost_per_1k_tokens": 0.0025,
          "description": "Claude 3 Haiku via AWS Bedrock"
        }
      ]
    },
    "ChatGoogleGenerativeAI": {
      "name": "ChatGoogleGenerativeAI",
      "display_name": "Google Gemini",
      "provider": "google",
      "class_name": "ChatGoogleGenerativeAI",
      "api_key_env_vars": ["GEMINI_API_KEY"],
      "base_url": "https://generativelanguage.googleapis.com",
      "default_model": "gemini-pro",
      "description": "Google Gemini models",
      "documentation_url": "https://ai.google.dev/docs",
      "is_local": false,
      "supported_models": [
        {
          "name": "gemini-pro",
          "display_name": "Gemini Pro",
          "model_id": "gemini-pro",
          "default_temperature": 0.7,
          "max_tokens": 2048,
          "supports_streaming": true,
          "supports_function_calling": true,
          "supports_vision": false,
          "cost_per_1k_tokens": 0.001,
          "description": "Google's most capable model"
        },
        {
          "name": "gemini-pro-vision",
          "display_name": "Gemini Pro Vision",
          "model_id": "gemini-pro-vision",
          "default_temperature": 0.7,
          "max_tokens": 2048,
          "supports_streaming": true,
          "supports_function_calling": false,
          "supports_vision": true,
          "cost_per_1k_tokens": 0.001,
          "description": "Gemini Pro with vision capabilities"
        },
        {
          "name": "gemini-1.5-pro",
          "display_name": "Gemini 1.5 Pro",
          "model_id": "gemini-1.5-pro",
          "default_temperature": 0.7,
          "max_tokens": 8192,
          "supports_streaming": true,
          "supports_function_calling": true,
          "supports_vision": true,
          "cost_per_1k_tokens": 0.0035,
          "description": "Latest Gemini model with enhanced capabilities"
        }
      ]
    },
    "ChatDeepSeek": {
      "name": "ChatDeepSeek",
      "display_name": "DeepSeek",
      "provider": "deepseek",
      "class_name": "ChatDeepSeek",
      "api_key_env_vars": ["DEEPSEEK_API_KEY"],
      "base_url": "https://api.deepseek.com",
      "default_model": "deepseek-chat",
      "description": "DeepSeek AI models",
      "documentation_url": "https://platform.deepseek.com/docs",
      "is_local": false,
      "supported_models": [
        {
          "name": "deepseek-chat",
          "display_name": "DeepSeek Chat",
          "model_id": "deepseek-chat",
          "default_temperature": 0.7,
          "max_tokens": 4096,
          "supports_streaming": true,
          "supports_function_calling": true,
          "supports_vision": false,
          "cost_per_1k_tokens": 0.0014,
          "description": "DeepSeek's main chat model"
        },
        {
          "name": "deepseek-coder",
          "display_name": "DeepSeek Coder",
          "model_id": "deepseek-coder",
          "default_temperature": 0.1,
          "max_tokens": 4096,
          "supports_streaming": true,
          "supports_function_calling": true,
          "supports_vision": false,
          "cost_per_1k_tokens": 0.0014,
          "description": "DeepSeek model optimized for coding tasks"
        }
      ]
    },
    "ChatQwQ": {
      "name": "ChatQwQ",
      "display_name": "Qwen (DashScope)",
      "provider": "dashscope",
      "class_name": "ChatQwQ",
      "api_key_env_vars": ["DASHSCOPE_API_KEY"],
      "base_url": "https://dashscope.aliyuncs.com",
      "default_model": "qwen-plus",
      "description": "Alibaba Qwen models via DashScope",
      "documentation_url": "https://help.aliyun.com/zh/dashscope/",
      "is_local": false,
      "supported_models": [
        {
          "name": "qwen-plus",
          "display_name": "Qwen Plus",
          "model_id": "qwen-plus",
          "default_temperature": 0.7,
          "max_tokens": 4096,
          "supports_streaming": true,
          "supports_function_calling": true,
          "supports_vision": false,
          "cost_per_1k_tokens": 0.008,
          "description": "Qwen's most capable model"
        },
        {
          "name": "qwen-turbo",
          "display_name": "Qwen Turbo",
          "model_id": "qwen-turbo",
          "default_temperature": 0.7,
          "max_tokens": 4096,
          "supports_streaming": true,
          "supports_function_calling": true,
          "supports_vision": false,
          "cost_per_1k_tokens": 0.003,
          "description": "Fast and efficient Qwen model"
        },
        {
          "name": "qwq-32b-preview",
          "display_name": "QwQ 32B Preview",
          "model_id": "qwq-32b-preview",
          "default_temperature": 0.7,
          "max_tokens": 4096,
          "supports_streaming": true,
          "supports_function_calling": false,
          "supports_vision": false,
          "cost_per_1k_tokens": 0.005,
          "description": "Qwen's reasoning-focused model"
        }
      ]
    },
    "ChatOllama": {
      "name": "ChatOllama",
      "display_name": "Ollama (Local)",
      "provider": "ollama",
      "class_name": "ChatOllama",
      "api_key_env_vars": [],
      "base_url": "http://localhost:11434",
      "default_model": "llama2",
      "description": "Local Ollama models",
      "documentation_url": "https://ollama.ai/docs",
      "is_local": true,
      "supported_models": [
        {
          "name": "llama2",
          "display_name": "Llama 2",
          "model_id": "llama2",
          "default_temperature": 0.7,
          "max_tokens": 2048,
          "supports_streaming": true,
          "supports_function_calling": false,
          "supports_vision": false,
          "cost_per_1k_tokens": 0.0,
          "description": "Meta's Llama 2 model"
        },
        {
          "name": "codellama",
          "display_name": "Code Llama",
          "model_id": "codellama",
          "default_temperature": 0.1,
          "max_tokens": 2048,
          "supports_streaming": true,
          "supports_function_calling": false,
          "supports_vision": false,
          "cost_per_1k_tokens": 0.0,
          "description": "Code-specialized Llama model"
        },
        {
          "name": "mistral",
          "display_name": "Mistral",
          "model_id": "mistral",
          "default_temperature": 0.7,
          "max_tokens": 2048,
          "supports_streaming": true,
          "supports_function_calling": false,
          "supports_vision": false,
          "cost_per_1k_tokens": 0.0,
          "description": "Mistral AI model"
        },
        {
          "name": "llama3.1",
          "display_name": "Llama 3.1",
          "model_id": "llama3.1",
          "default_temperature": 0.7,
          "max_tokens": 4096,
          "supports_streaming": true,
          "supports_function_calling": false,
          "supports_vision": false,
          "cost_per_1k_tokens": 0.0,
          "description": "Latest Llama 3.1 model"
        }
      ]
    }
  },
  "metadata": {
    "version": "1.0.0",
    "last_updated": "2025-01-16",
    "description": "LLM provider configurations for eCan.ai",
    "schema_version": "1.0"
  }
}
