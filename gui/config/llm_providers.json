{
  "providers": {
    "OpenAI": {
      "name": "OpenAI",
      "display_name": "OpenAI",
      "provider": "openai",
      "class_name": "ChatOpenAI",
      "api_key_env_vars": [
        "OPENAI_API_KEY"
      ],
      "base_url": "https://api.openai.com/v1",
      "default_model": "gpt-5",
      "description": "OpenAI models including the latest GPT-5 and O-series",
      "documentation_url": "https://platform.openai.com/docs/models",
      "is_local": false,
      "supported_models": [
        {
          "name": "gpt-5.1",
          "display_name": "GPT-5.1",
          "model_id": "gpt-5.1",
          "default_temperature": 0.7,
          "max_tokens": 200000,
          "supports_streaming": true,
          "supports_function_calling": true,
          "supports_vision": true,
          "cost_per_1k_tokens": 0.005,
          "description": "Advanced GPT-5.1 model with enhanced reasoning"
        },
        {
          "name": "gpt-5",
          "display_name": "GPT-5",
          "model_id": "gpt-5",
          "default_temperature": 0.7,
          "max_tokens": 131072,
          "supports_streaming": true,
          "supports_function_calling": true,
          "supports_vision": true,
          "cost_per_1k_tokens": 0.003,
          "description": "OpenAI's 2025 flagship multimodal model"
        },
        {
          "name": "o4-mini",
          "display_name": "O4 Mini",
          "model_id": "o4-mini",
          "default_temperature": 1.0,
          "max_tokens": 100000,
          "supports_streaming": true,
          "supports_function_calling": true,
          "supports_vision": true,
          "cost_per_1k_tokens": 0.001,
          "description": "Highly efficient O-series reasoning model (AIME 2025 SOTA)"
        },
        {
          "name": "o3-pro",
          "display_name": "O3 Pro",
          "model_id": "o3-pro",
          "default_temperature": 1.0,
          "max_tokens": 200000,
          "supports_streaming": true,
          "supports_function_calling": true,
          "supports_vision": true,
          "cost_per_1k_tokens": 0.02,
          "description": "Powerful reasoning model (June 2025)"
        },
        {
          "name": "gpt-4o",
          "display_name": "GPT-4o",
          "model_id": "gpt-4o",
          "default_temperature": 0.7,
          "max_tokens": 128000,
          "supports_streaming": true,
          "supports_function_calling": true,
          "supports_vision": true,
          "cost_per_1k_tokens": 0.0025,
          "description": "Previous generation flagship"
        }
      ]
    },
    "Anthropic Claude": {
      "name": "Anthropic Claude",
      "display_name": "Anthropic Claude",
      "provider": "anthropic",
      "class_name": "ChatAnthropic",
      "api_key_env_vars": [
        "ANTHROPIC_API_KEY"
      ],
      "base_url": "https://api.anthropic.com",
      "default_model": "claude-sonnet-4.5",
      "description": "Anthropic Claude models",
      "documentation_url": "https://docs.anthropic.com/",
      "is_local": false,
      "supported_models": [
        {
          "name": "claude-opus-4.5",
          "display_name": "Claude Opus 4.5",
          "model_id": "claude-opus-4.5",
          "default_temperature": 0.7,
          "max_tokens": 200000,
          "supports_streaming": true,
          "supports_function_calling": true,
          "supports_vision": true,
          "cost_per_1k_tokens": 0.02,
          "description": "Most intelligent Claude model (Nov 2025)"
        },
        {
          "name": "claude-sonnet-4.5",
          "display_name": "Claude Sonnet 4.5",
          "model_id": "claude-sonnet-4.5",
          "default_temperature": 0.7,
          "max_tokens": 200000,
          "supports_streaming": true,
          "supports_function_calling": true,
          "supports_vision": true,
          "cost_per_1k_tokens": 0.003,
          "description": "Balanced intelligence and speed (July 2025)"
        }
      ]
    },
    "Google Gemini": {
      "name": "Google Gemini",
      "display_name": "Google Gemini",
      "provider": "google",
      "class_name": "ChatGoogleGenerativeAI",
      "api_key_env_vars": [
        "GEMINI_API_KEY"
      ],
      "base_url": "https://generativelanguage.googleapis.com/v1beta/",
      "default_model": "gemini-3.0-pro",
      "description": "Google Gemini models",
      "documentation_url": "https://ai.google.dev/docs",
      "is_local": false,
      "supported_models": [
        {
          "name": "gemini-3.0-pro",
          "display_name": "Gemini 3.0 Pro",
          "model_id": "gemini-3.0-pro",
          "default_temperature": 0.7,
          "max_tokens": 2000000,
          "supports_streaming": true,
          "supports_function_calling": true,
          "supports_vision": true,
          "cost_per_1k_tokens": 0.0035,
          "description": "Next-gen Gemini 3.0 Pro model"
        }
      ]
    },
    "DeepSeek": {
      "name": "DeepSeek",
      "display_name": "DeepSeek",
      "provider": "deepseek",
      "class_name": "ChatDeepSeek",
      "api_key_env_vars": [
        "DEEPSEEK_API_KEY"
      ],
      "base_url": "https://api.deepseek.com",
      "default_model": "deepseek-chat",
      "description": "DeepSeek AI models",
      "documentation_url": "https://platform.deepseek.com/",
      "is_local": false,
      "supported_models": [
        {
          "name": "deepseek-chat",
          "display_name": "DeepSeek-V3",
          "model_id": "deepseek-chat",
          "default_temperature": 1.3,
          "max_tokens": 128000,
          "supports_streaming": true,
          "supports_function_calling": true,
          "supports_vision": false,
          "cost_per_1k_tokens": 0.00014,
          "description": "DeepSeek-V3: Mixture-of-Experts model (Dec 2024)"
        },
        {
          "name": "deepseek-reasoner",
          "display_name": "DeepSeek-R1",
          "model_id": "deepseek-reasoner",
          "default_temperature": 0.6,
          "max_tokens": 64000,
          "supports_streaming": true,
          "supports_function_calling": false,
          "supports_vision": false,
          "cost_per_1k_tokens": 0.00055,
          "description": "DeepSeek-R1: Advanced reasoning model (Jan 2025)"
        }
      ]
    },
    "Qwen (DashScope)": {
      "name": "Qwen (DashScope)",
      "display_name": "Qwen (DashScope)",
      "provider": "dashscope",
      "class_name": "ChatQwQ",
      "api_key_env_vars": [
        "DASHSCOPE_API_KEY"
      ],
      "base_url": "https://dashscope.aliyuncs.com/compatible-mode/v1",
      "default_model": "qwen-max",
      "description": "Alibaba Qwen models via DashScope (Qwen 3 / 2.5)",
      "documentation_url": "https://help.aliyun.com/zh/model-studio/getting-started/models",
      "is_local": false,
      "supported_models": [
        {
          "name": "qwen-max",
          "display_name": "Qwen Max",
          "model_id": "qwen-max",
          "default_temperature": 0.7,
          "max_tokens": 32768,
          "supports_streaming": true,
          "supports_function_calling": true,
          "supports_vision": true,
          "cost_per_1k_tokens": 0.01,
          "description": "Flagship Qwen model (Likely Qwen 3 based)"
        },
        {
          "name": "qwen-plus",
          "display_name": "Qwen Plus",
          "model_id": "qwen-plus",
          "default_temperature": 0.7,
          "max_tokens": 32768,
          "supports_streaming": true,
          "supports_function_calling": true,
          "supports_vision": true,
          "cost_per_1k_tokens": 0.004,
          "description": "Balanced Qwen model"
        },
        {
          "name": "qwen-turbo",
          "display_name": "Qwen Turbo",
          "model_id": "qwen-turbo",
          "default_temperature": 0.7,
          "max_tokens": 32768,
          "supports_streaming": true,
          "supports_function_calling": true,
          "supports_vision": false,
          "cost_per_1k_tokens": 0.002,
          "description": "Fast Qwen model"
        }
      ]
    },
    "Bytedance": {
      "name": "Bytedance",
      "display_name": "Bytedance",
      "provider": "bytedance",
      "class_name": "ChatDoubao",
      "api_key_env_vars": [
        "ARK_API_KEY"
      ],
      "base_url": "https://ark.cn-beijing.volces.com/api/v3",
      "default_model": "doubao-pro-32k",
      "description": "Bytedance Doubao models",
      "documentation_url": "https://www.volcengine.com/docs/82379",
      "is_local": false,
      "supported_models": [
        {
          "name": "doubao-pro-32k",
          "display_name": "Doubao Pro 32K",
          "model_id": "doubao-pro-32k",
          "default_temperature": 0.7,
          "max_tokens": 32000,
          "supports_streaming": true,
          "supports_function_calling": true,
          "supports_vision": false,
          "cost_per_1k_tokens": 0.0008,
          "description": "Doubao Pro 32K"
        },
        {
          "name": "doubao-pro-128k",
          "display_name": "Doubao Pro 128K",
          "model_id": "doubao-pro-128k",
          "default_temperature": 0.7,
          "max_tokens": 128000,
          "supports_streaming": true,
          "supports_function_calling": true,
          "supports_vision": false,
          "cost_per_1k_tokens": 0.005,
          "description": "Doubao Pro 128K"
        }
      ]
    },
    "Baidu Qianfan": {
      "name": "Baidu Qianfan",
      "display_name": "Baidu Qianfan",
      "provider": "baidu_qianfan",
      "class_name": "ChatBaiduQianfan",
      "api_key_env_vars": [
        "BAIDU_API_KEY"
      ],
      "base_url": "https://qianfan.baidubce.com/v2",
      "default_model": "ernie-4.0-turbo-128k",
      "description": "Baidu Wenxin (ERNIE) models - OpenAI compatible API v2",
      "documentation_url": "https://cloud.baidu.com/doc/WENXINWORKSHOP/s/Hlwerupz6",
      "is_local": false,
      "supported_models": [
        {
          "name": "ernie-4.0-turbo-128k",
          "display_name": "ERNIE 4.0 Turbo 128K",
          "model_id": "ernie-4.0-turbo-128k",
          "default_temperature": 0.7,
          "max_tokens": 131072,
          "supports_streaming": true,
          "supports_function_calling": true,
          "supports_vision": true,
          "cost_per_1k_tokens": 0.12,
          "description": "ERNIE 4.0 Turbo with long context"
        },
        {
          "name": "ernie-4.0-turbo-8k",
          "display_name": "ERNIE 4.0 Turbo 8K",
          "model_id": "ernie-4.0-turbo-8k",
          "default_temperature": 0.7,
          "max_tokens": 8192,
          "supports_streaming": true,
          "supports_function_calling": true,
          "supports_vision": true,
          "cost_per_1k_tokens": 0.12,
          "description": "ERNIE 4.0 Turbo"
        },
        {
          "name": "ernie-speed-128k",
          "display_name": "ERNIE Speed 128K",
          "model_id": "ernie-speed-128k",
          "default_temperature": 0.7,
          "max_tokens": 128000,
          "supports_streaming": true,
          "supports_function_calling": true,
          "supports_vision": false,
          "cost_per_1k_tokens": 0.0,
          "description": "ERNIE Speed"
        }
      ]
    },
    "Azure OpenAI": {
      "name": "Azure OpenAI",
      "display_name": "Azure OpenAI",
      "provider": "azure_openai",
      "class_name": "AzureOpenAI",
      "api_key_env_vars": [
        "AZURE_ENDPOINT",
        "AZURE_OPENAI_API_KEY"
      ],
      "base_url": "https://your-resource.openai.azure.com",
      "default_model": "gpt-4o",
      "description": "Azure OpenAI Service",
      "documentation_url": "https://learn.microsoft.com/en-us/azure/ai-services/openai/",
      "is_local": false,
      "supported_models": [
        {
          "name": "gpt-4o",
          "display_name": "GPT-4o (Azure)",
          "model_id": "gpt-4o",
          "default_temperature": 0.7,
          "max_tokens": 128000,
          "supports_streaming": true,
          "supports_function_calling": true,
          "supports_vision": true,
          "cost_per_1k_tokens": 0.0025,
          "description": "GPT-4o on Azure"
        },
        {
          "name": "gpt-4o-mini",
          "display_name": "GPT-4o Mini (Azure)",
          "model_id": "gpt-4o-mini",
          "default_temperature": 0.7,
          "max_tokens": 128000,
          "supports_streaming": true,
          "supports_function_calling": true,
          "supports_vision": true,
          "cost_per_1k_tokens": 0.00015,
          "description": "GPT-4o Mini on Azure"
        }
      ]
    },
    "AWS Bedrock": {
      "name": "AWS Bedrock",
      "display_name": "AWS Bedrock",
      "provider": "bedrock",
      "class_name": "ChatBedrockConverse",
      "api_key_env_vars": [
        "AWS_ACCESS_KEY_ID",
        "AWS_SECRET_ACCESS_KEY"
      ],
      "base_url": "https://bedrock-runtime.us-east-1.amazonaws.com",
      "default_model": "anthropic.claude-3-5-sonnet-20240620-v1:0",
      "description": "AWS Bedrock Converse API",
      "documentation_url": "https://docs.aws.amazon.com/bedrock/latest/userguide/model-ids.html",
      "is_local": false,
      "supported_models": [
        {
          "name": "anthropic.claude-3-5-sonnet-20240620-v1:0",
          "display_name": "Claude 3.5 Sonnet (Bedrock)",
          "model_id": "anthropic.claude-3-5-sonnet-20240620-v1:0",
          "default_temperature": 0.7,
          "max_tokens": 200000,
          "supports_streaming": true,
          "supports_function_calling": true,
          "supports_vision": true,
          "cost_per_1k_tokens": 0.003,
          "description": "Claude 3.5 Sonnet via Bedrock"
        },
        {
          "name": "meta.llama3-1-70b-instruct-v1:0",
          "display_name": "Llama 3.1 70B Instruct",
          "model_id": "meta.llama3-1-70b-instruct-v1:0",
          "default_temperature": 0.7,
          "max_tokens": 128000,
          "supports_streaming": true,
          "supports_function_calling": true,
          "supports_vision": false,
          "cost_per_1k_tokens": 0.00099,
          "description": "Meta Llama 3.1 70B via Bedrock"
        }
      ]
    },
    "Ollama (Local)": {
      "name": "Ollama (Local)",
      "display_name": "Ollama (Local)",
      "provider": "ollama",
      "class_name": "ChatOpenAI",
      "api_key_env_vars": [
        "OLLAMA_LLM_API_KEY"
      ],
      "base_url": "http://localhost:11434",
      "default_model": "",
      "description": "Local Ollama models (native API for LightRAG, auto-converts to OpenAI-compatible /v1 for ChatOpenAI)",
      "documentation_url": "https://ollama.com/library",
      "is_local": true,
      "supported_models": []
    }
  },
  "metadata": {
    "version": "1.1.1",
    "last_updated": "2025-11-26",
    "description": "LLM provider configurations for eCan.ai - Updated for Nov 2025",
    "schema_version": "1.0"
  }
}